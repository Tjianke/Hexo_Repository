# 机器学习
机器学习正如其字面意思，就是计算机（严格说是计算机程序）能够通过自主学习而变得越来越聪明。简单的机器学习过程，就是通过喂给机器某一类现存大量初始条件和已知正确结果的数据（可以称为教材），外加一个数学模型 （带有一些参数的公式，也称算法），让程序通过反复运算，不断调整这些参数，直至得到一组“最佳”的参数。一旦有了这些“最佳”参数，机器可以近乎完美地算出对应的正确结果。如此这般，机器就“学会”处理这一类数据的本领，可以用来计算出比较可信的结果，例如诊断疾病，预测天气，识别图像，下棋，自动驾驶等等。

## 机器学习历史

机器学习并不是一个新的理论。上世纪 50 年代就有人提出了一些机器学习算法。但因为这些传统的早期算法不够聪明，能解决的问题有限，处理不了复杂问题，这个分支一直没有大的进展。这些年机器学习的成功更多是归功于深度学习方面的进展。深度学习的理论也已经成型很久，但由于中间隐藏层的误差无法准确计算，所以很难实际应用。直到 1986 年有人提出了反向传播算法（Back Propagation， BP），深度学习才有长足进步和实际应用的可能。

![Relationship between AI, ML and DL](http://upload.xingkongmt.com/images/5085/20170807/3db251ec-afb8-42de-9e0c-52e562dc94ea.jpeg)
<p align="center">Relationship between AI, ML and DL</p>

人工智能(AI),机器学习(ML), 和深度学习(DL)并不是一回事。深度学习(DL)是机器学习(ML)的主要算法，而机器学习(ML)是人工智能(AI)的核心功能(图三)。深度学习的算法尽管已经比较成熟，但在实际应用中还会遇到各种挑战，比如要得到最佳参数需要喂给机器大量数据让机器自己学习。数据越多，机器就越聪明。而处理大量数据就会遇到大数据的问题，解决的办法主要是靠分布式存储和计算。 

机器学习可以分为以下三大种类：
![Types of Machine Learning](https://sg.fiverrcdn.com/photos/75648476/original/f303394129c0b6352c43235b6fae39b522b1dfb8.png?1485029457)

## Supervised Learning (监督学习)：

>从给定输入和输出的数据中建立一个函数，并依此函数推测新的输出。

简单来说，计量经济学中的模型都可以归类为监督学习。根据各种输入（X）预测与输出（Y）之间是否存在关联。

![房价预测模型](http://7xrrje.com1.z0.glb.clouddn.com/img_1.jpg?imageMogr/v2/thumbnail/!45p)
<p align='center'>回归：根据房屋面积预测房价</p>

![肿瘤预测为题](http://7xrrje.com1.z0.glb.clouddn.com/img_1022aa.jpg?imageMogr/v2/thumbnail/!45p)
<p align='center'>分类：根据肿瘤大小预测恶心肿瘤</p>

监督学习和无监督学习的区别就在于监督学习的数据不仅仅有特征组成, 即每一个数据样本都包含一个准确的输出值（房价、肿瘤是否恶性）。

## Unsupervised Learning (非监督学习)
>在无监督学习中, 我们的数据并没有给出特定的标签(如上例中的房价或肿瘤性质）。 我们目标也从预测输出变为寻找数据的结构特性。

如下图所示, 我们可以直观的感受到监督学习和无监督学习在数据集上的区别。
![Difference](http://7xrrje.com1.z0.glb.clouddn.com/screenshot_582.png?imageMogr/v2/thumbnail/!55p)
<p align='center'>监督式学习和非监督式学习的差异</p>

![Unsupervised Learning](https://nowenlightenme.files.wordpress.com/2018/03/slide_2.jpg)
当然图片上的分类算法仅仅包括两个维度的数据（x,y）。业界运用的非监督学习所涉及到的数据维度往往较大，但是聚类的方法仍然类似。
常用算法推荐：？

## Reinforcement Learning （强化学习）

在强化学习（RL）中没有原始已知数据可以学习。强化学习面对的是一个不断变化的状态空间，要解决的是一个决策链问题。其目的是找到在当前环境（状态空间）下最佳决策是什么。这里的挑战是，当下的决策好坏当下无法立刻验证和评估，要根据多次决策以后才能知道。机器需要在变化的环境中通过大量的多次的试错学习，再根据某种规则找到产生最佳结果的最佳路径，从而做出最佳决策。常见的应用有**下棋**、**自动驾驶**等。

让我们看看人类棋手的决策过程：
>人类棋手根据当下棋盘上情况找到他（她）认为是最佳的下一步棋的落点。高手一般能看到后面的几步棋，从而确定走哪一步对自己最有利。这个过程可以用计算机来模拟，我们把从现在开始所有可能的走法（也称之为路径）逐个试一遍，从而选出下一步棋的最佳方案。这种简单粗暴的方法穷尽了所有的可能路径，必定旗开得胜。

AlphaGo利用大量高手(3000万)对弈棋谱，通过13层的深度卷积神经网络（Convolutional Neural Network， CNN）计算出这些高手们在某个棋盘状态时下一手在某个位置落子的概率（落子概率）。输入值是棋子的方格位置状态，输出值是在某一位置下棋的概率，所以这里应用了监督学习的算法。

这样，阿尔法狗通过强化学习知道了每一个试过的走法的赢棋概率。但是还有大量的没有试过的走法，在这些走法里面有可能存在很多赢棋概率的走法。为了解决这个问题，阿尔法狗又使用了新的学习过程：本来每次落子蒙特卡罗方法都会算出最佳走法，但在左右互搏时加入一定的随机走法以不断扩展探索空间寻找更佳走法的棋谱。然后根据新的棋谱产生更好的赢棋概率分布。这个过程会不断地重复。通过这样的自我训练学习，阿尔法狗的能力不断提高。
#### 阿法狗的局限
阿尔法狗（AlphaGo）战胜人类是人工智能的一个巨大突破，也跌破了很多人的眼镜。特别是阿尔法狗能自我学习，让很多人以为它啥都能学会，一定会超过人类。这显然是对阿尔法狗的误解。到目前为止，机器学习多是找到喂给机器的数据里的特征或者模式，而且里面用到的模型也只适合那些数据，对其他种类的数据就无能为力。既是强化学习，也是根据已知规则来学习评估，这些规则和评估方式对另外一个环境就完全不适用了。换一句话说，当前的机器学习都是特定能力的学习。能够像人类一样，可以学习不同的东西、具有广泛学习能力的机器到现在还没有出现。




